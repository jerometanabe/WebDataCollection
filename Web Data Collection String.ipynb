{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dependencies\n",
    "import requests\n",
    "import time\n",
    "import datetime as dt\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca013eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating CSV that links collected from each store page will be added to\n",
    "header = ['title','link', 'dateAccessed']\n",
    "with open('ProductURL.csv', 'w', newline = '', encoding = 'UTF8') as b:\n",
    "    writer = csv.writer(b)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "#Creating CSV that information from each product will be added to\n",
    "productHeader = ['title', 'genre', 'price', 'quantity', 'inStock', 'UPC', 'productType', 'dateAccessed']\n",
    "with open('ProductInformation.csv', 'w', newline = '', encoding = 'UTF8') as a:\n",
    "    writer = csv.writer(a)\n",
    "    writer.writerow(productHeader)\n",
    "\n",
    "#Function for extracting product information\n",
    "def productExtract(url):\n",
    "    page = requests.get(url, headers = headers)\n",
    "    soup = BS(page.content, 'html.parser')\n",
    "\n",
    "    #Select the title\n",
    "    title = soup.html.title.text\n",
    "    title = title[:title.index('|')].strip()\n",
    "\n",
    "    #Select the genre, which is only located in a breadcrumb list\n",
    "    genre = soup.find('ul').text\n",
    "    #Create list of breadcrumb items\n",
    "    genre = genre.split('\\n')\n",
    "    genre = list(filter(None, genre))[-2]\n",
    "\n",
    "    #Selecting price\n",
    "    price = soup.find(class_ = 'price_color').get_text()\n",
    "\n",
    "    #Selecting quantity and availability (inStock)\n",
    "    #Returns a statement ie: 'In stock (21) available'\n",
    "    availability = soup.find(class_ = 'instock availability').text\n",
    "\n",
    "    #Selecting quantity by filtering numeric values into a list\n",
    "    quantity = re.findall(r'\\d+', availability)[0]\n",
    "\n",
    "    #Using quantity to determine availability\n",
    "    quantity = int(quantity)\n",
    "    if quantity <= 0:\n",
    "        inStock = 'no'\n",
    "    else:\n",
    "        inStock = 'yes'\n",
    "\n",
    "    #Selecting UPC and product type\n",
    "    UPC = soup.html.table.td.text\n",
    "    productType = list(soup.find_all('td'))[1].text\n",
    "\n",
    "    #Determine when data was accessed\n",
    "    dateAccessed = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    #Write results onto CSV with product information\n",
    "    results = [title, genre, price, quantity, inStock, UPC, productType, dateAccessed]\n",
    "    with open('ProductInformation.csv', 'a+', newline = '', encoding = 'UTF8') as a:\n",
    "        writer = csv.writer(a)\n",
    "        writer.writerow(results)\n",
    "        \n",
    "#Function for collecting URL for every product in store page\n",
    "def pageCollect(url2):\n",
    "    page = requests.get(url2)\n",
    "    soup = BS(page.content, 'html.parser')\n",
    "    \n",
    "    #Collect all containers containing product title and link\n",
    "    bookContainers = soup.find_all(\"li\", {'class':'col-xs-6 col-sm-4 col-md-3 col-lg-3'})\n",
    "\n",
    "    for container in bookContainers:\n",
    "        #Select title\n",
    "        containerTitle = container.find('a').find('img').get('alt')\n",
    "        \n",
    "        #Select link\n",
    "        href = container.find('a').get('href')\n",
    "        bookLink = 'https://books.toscrape.com/catalogue/' + href\n",
    "        \n",
    "        #Determine when data was accessed\n",
    "        dateAccessed = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        \n",
    "        #Write results onto CSV with product links\n",
    "        row = (containerTitle, bookLink, dateAccessed)\n",
    "        with open('ProductURL.csv', 'a+', newline = '\\n', encoding = 'UTF8') as b:\n",
    "            writer = csv.writer(b)\n",
    "            writer.writerow(row)\n",
    "        productExtract(bookLink)\n",
    "        \n",
    "#Finds total number of product store pages\n",
    "#Returns string ie: 'Page 1 of x (x = number of pages)'\n",
    "pageNum = soup.find(\"ul\", {\"class\": \"pager\"}).text.strip()\n",
    "pageTotal = int(pageNum[pageNum.index('of') + 3 : pageNum.index('next')])\n",
    "\n",
    "#For moving between pages\n",
    "#GENERATES A NEW URL\n",
    "for i in range(1, pageTotal + 1):\n",
    "    print('Currently parsing through page ' + str(i) + '.')\n",
    "    URL = 'https://books.toscrape.com/catalogue/page-' + str(i) + '.html'\n",
    "    pageCollect(URL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
